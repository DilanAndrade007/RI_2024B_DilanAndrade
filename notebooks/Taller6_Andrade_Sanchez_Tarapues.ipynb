{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 06: Bases de Datos Vectoriales  \n",
    "**ICCD753 Recuperación de Información – Prof. Iván Carrera (2024-B, EPN-FIS)**  \n",
    "\n",
    "**Fecha de Entrega:** Martes 14 de enero de 2025  \n",
    "**Integrantes:**  \n",
    "- Dilan Andrade  \n",
    "- Hernán Sánchez  \n",
    "- Galo Tarapués  \n",
    "\n",
    "---\n",
    "\n",
    "### **Objetivo del Taller**\n",
    "Implementar y comparar estrategias de recuperación de información utilizando TF-IDF, BM25 y embeddings con bases de datos vectoriales, evaluando su relevancia y eficiencia en un dataset textual real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte1 Recuperación con TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 1: Importación de Librerías para TF-IDF**\n",
    "En esta celda se importan las librerías fundamentales para la implementación de la recuperación de información utilizando el modelo TF-IDF. Estas librerías permiten:\n",
    "\n",
    "1. **`pandas`**: Manejar y procesar el dataset estructurado del taller.\n",
    "2. **`TfidfVectorizer`** (de `scikit-learn`): Transformar los textos en una matriz TF-IDF, donde cada documento es representado como un vector en un espacio de palabras.\n",
    "3. **`cosine_similarity`** (de `scikit-learn`): Calcular la similitud entre vectores de documentos y consultas, para determinar qué tan relevante es un documento en relación con la consulta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd  # Para la manipulación de datos\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Para calcular la matriz TF-IDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Para calcular similitud entre vectores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 2: Carga y Preprocesamiento del Dataset**\n",
    "En esta celda se realiza la carga y preprocesamiento inicial del dataset `Wikipedia Movie Plots`. Los pasos incluyen:\n",
    "\n",
    "1. **Definir la ruta del dataset**: Se especifica la ubicación del archivo CSV (`wiki_movie_plots_deduped.csv`).\n",
    "2. **Cargar el dataset**: Se utiliza `pandas` para cargar el archivo CSV en un DataFrame, que permite manipular y analizar los datos.\n",
    "3. **Eliminación de filas inválidas**: Se eliminan las filas que no contienen información válida en la columna `Plot`, ya que esta información es esencial para la tarea de recuperación.\n",
    "4. **Verificación de datos**: Se muestran las primeras filas del DataFrame para asegurarse de que la carga y el preprocesamiento sean correctos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "\n",
       "                             Director Cast    Genre  \\\n",
       "0                             Unknown  NaN  unknown   \n",
       "1                             Unknown  NaN  unknown   \n",
       "2                             Unknown  NaN  unknown   \n",
       "3                             Unknown  NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir la ruta del dataset\n",
    "ruta_dataset = \"wiki_movie_plots_deduped.csv\"\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame de pandas\n",
    "df = pd.read_csv(ruta_dataset)\n",
    "\n",
    "# Eliminar filas sin un 'Plot' válido\n",
    "df = df.dropna(subset=['Plot'])\n",
    "\n",
    "# Mostrar las primeras filas para verificar la carga de datos\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 3: Combinación de Título y Trama para el Modelo TF-IDF**\n",
    "En esta celda se integra la información del título y la trama de cada película en una nueva columna llamada `texto_completo`. Este paso es crucial para que el modelo TF-IDF considere tanto el título como el contenido de la trama durante la extracción de características. \n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Integración de datos**: Se crea la columna `texto_completo` combinando el título (`Title`) y la trama (`Plot`) de cada película.\n",
    "2. **Posibilidad de preprocesamiento adicional**:\n",
    "   - Conversión a minúsculas para normalizar el texto.\n",
    "   - Aplicación de expresiones regulares, lematización o stemming para mejorar la calidad del texto procesado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar el título y la trama en una nueva columna 'texto_completo'\n",
    "df['texto_completo'] = df['Title'].astype(str) + \" \" + df['Plot'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 4: Configuración y Generación de la Matriz TF-IDF**\n",
    "En esta celda se configura y genera la matriz TF-IDF para representar los documentos del dataset como vectores numéricos, listos para ser utilizados en cálculos de similitud.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Configuración del `TfidfVectorizer`**:\n",
    "   - `stop_words='english'`: Elimina palabras comunes en inglés (stopwords) que no aportan valor semántico.\n",
    "   - `max_features=20000`: Limita el vocabulario a las 20,000 palabras más importantes según la frecuencia.\n",
    "   - `sublinear_tf=True`: Aplica una escala logarítmica a las frecuencias para reducir el impacto de palabras extremadamente frecuentes.\n",
    "   - `ngram_range=(1, 2)`: Captura unigramas (palabras individuales) y bigramas (pares de palabras consecutivas).\n",
    "   \n",
    "2. **Transformación de los documentos**:\n",
    "   - Se ajusta el vectorizador a la columna `texto_completo`, generando una matriz TF-IDF.\n",
    "   - Cada fila de la matriz representa un documento, y cada columna, una palabra o bigrama en el vocabulario.\n",
    "\n",
    "3. **Salida**:\n",
    "   - La forma de la matriz (`n_documentos`, `n_features`) es impresa para verificar la correcta generación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz TF-IDF generada con forma: (34886, 20000)\n"
     ]
    }
   ],
   "source": [
    "# Configurar el vectorizador TF-IDF con parámetros ajustados\n",
    "vectorizador_tfidf = TfidfVectorizer(\n",
    "    stop_words='english',  # Remover stopwords en inglés\n",
    "    max_features=20000,  # Limitar el vocabulario a 20,000 palabras\n",
    "    sublinear_tf=True,  # Usar escala logarítmica para frecuencias\n",
    "    ngram_range=(1, 2)  # Capturar unigramas y bigramas\n",
    ")\n",
    "\n",
    "# Generar la matriz TF-IDF ajustando el vectorizador a la columna 'texto_completo'\n",
    "matriz_tfidf = vectorizador_tfidf.fit_transform(df['texto_completo'])\n",
    "\n",
    "# Imprimir la forma de la matriz para verificar\n",
    "print(\"Matriz TF-IDF generada con forma:\", matriz_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 5: Función para Realizar Búsquedas con TF-IDF**\n",
    "Esta celda define una función que permite realizar búsquedas en el dataset utilizando el modelo TF-IDF. Dada una consulta de texto, la función encuentra los documentos más relevantes mediante el cálculo de la similitud de coseno entre la consulta y los documentos del dataset.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Transformación de la consulta**:\n",
    "   - La consulta se transforma en un vector TF-IDF utilizando los mismos parámetros con los que se entrenó el vectorizador original.\n",
    "   \n",
    "2. **Cálculo de similitud**:\n",
    "   - Se calcula la similitud de coseno entre el vector de la consulta y todos los documentos del dataset.\n",
    "   \n",
    "3. **Ordenamiento de resultados**:\n",
    "   - Los documentos se ordenan en función de su puntuación de similitud en orden descendente.\n",
    "   - Se retornan los índices de los documentos más relevantes y sus puntuaciones.\n",
    "\n",
    "#### Parámetros:\n",
    "- `consulta` (str): Texto de la consulta a buscar.\n",
    "- `numero_resultados` (int): Número de documentos más relevantes a devolver (por defecto, 5).\n",
    "\n",
    "#### Retorno:\n",
    "- `indices_ordenados`: Índices de los documentos más relevantes.\n",
    "- `puntuaciones`: Puntuaciones de similitud correspondientes a los documentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_con_tfidf(consulta, numero_resultados=5):\n",
    "    # Convertir la consulta al vector TF-IDF\n",
    "    vector_consulta = vectorizador_tfidf.transform([consulta])\n",
    "\n",
    "    # Calcular similitud de coseno con todos los documentos\n",
    "    similitudes = cosine_similarity(vector_consulta, matriz_tfidf).flatten()\n",
    "\n",
    "    # Ordenar documentos por puntuación de similitud (descendente)\n",
    "    indices_ordenados = similitudes.argsort()[::-1][:numero_resultados]\n",
    "    puntuaciones = similitudes[indices_ordenados]\n",
    "\n",
    "    return indices_ordenados, puntuaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 6: Ejemplo de Consulta con TF-IDF**\n",
    "En esta celda se realiza una consulta de ejemplo utilizando la función `buscar_con_tfidf`, previamente definida. El propósito es recuperar los documentos más relevantes para una consulta específica y mostrar información útil sobre ellos.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Consulta de ejemplo**:\n",
    "   - La consulta `\"dinosaurs\"` se utiliza para probar el sistema de búsqueda.\n",
    "   \n",
    "2. **Recuperación de documentos**:\n",
    "   - La función `buscar_con_tfidf` retorna los índices y las puntuaciones de los documentos más relevantes en el dataset.\n",
    "   \n",
    "3. **Visualización de resultados**:\n",
    "   - Por cada documento relevante, se imprime:\n",
    "     - **Rango**: Posición del documento en el ranking.\n",
    "     - **Título**: El título de la película.\n",
    "     - **Similitud**: Puntuación de similitud calculada con el modelo TF-IDF.\n",
    "     - **Trama**: Los primeros 200 caracteres de la trama, para evitar saturar la salida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para la consulta: 'dinosaurs'\n",
      "\n",
      "Rank 1\n",
      "Título (Title): Theodore Rex\n",
      "Similitud: 0.3514\n",
      "Trama (Plot) (primeros 200 caracteres): In an alternate futuristic society where humans and anthropomorphic dinosaurs co-exist, a tough police detective named Katie Coltraine (Whoopi Goldberg) is paired with a Tyrannosaurus named Theodore R...\n",
      "--------------------------------------------------\n",
      "Rank 2\n",
      "Título (Title): Dinosaurs! – A Fun-Filled Trip Back in Time!\n",
      "Similitud: 0.2623\n",
      "Trama (Plot) (primeros 200 caracteres): The video—with beginning scenes filmed in 1987—begins with a young boy named Phillip (played by Fred Savage) sitting in his bedroom, listening to loud music, and struggling to find an idea for a class...\n",
      "--------------------------------------------------\n",
      "Rank 3\n",
      "Título (Title): We're Back! A Dinosaur's Story\n",
      "Similitud: 0.2593\n",
      "Trama (Plot) (primeros 200 caracteres): In present-day New York City, an Eastern bluebird named Buster runs away from his siblings and he meets an intelligent orange Tyrannosaurus named Rex, who is playing golf. He explains to Buster that h...\n",
      "--------------------------------------------------\n",
      "Rank 4\n",
      "Título (Title): Future War\n",
      "Similitud: 0.2569\n",
      "Trama (Plot) (primeros 200 caracteres): Future War begins aboard a spaceship undergoing a revolt. A man enters and activates an escape pod which travels to Earth and crashes into the Pacific Ocean. The pod contains “The Runaway”, a human sl...\n",
      "--------------------------------------------------\n",
      "Rank 5\n",
      "Título (Title): Abaranger Deluxe\n",
      "Similitud: 0.2505\n",
      "Trama (Plot) (primeros 200 caracteres): Scientists believe that 65,000,000 years ago, a meteorite's crash on Earth killed off the dinosaurs, but in truth, it split Earth into two parallel universes: Dino Earth (ダイノアース, Daino Aasu), an Earth...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de consulta\n",
    "consulta_ejemplo = \"dinosaurs\"\n",
    "\n",
    "# Obtener los documentos más similares\n",
    "indices_encontrados, puntuaciones_encontradas = buscar_con_tfidf(consulta_ejemplo, numero_resultados=5)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Resultados para la consulta: '{consulta_ejemplo}'\\n\")\n",
    "for rank, (indice, puntuacion) in enumerate(zip(indices_encontrados, puntuaciones_encontradas), start=1):\n",
    "    print(f\"Rank {rank}\")\n",
    "    print(f\"Título (Title): {df.loc[indice, 'Title']}\")\n",
    "    print(f\"Similitud: {puntuacion:.4f}\")\n",
    "    # Mostrar los primeros 200 caracteres de la trama\n",
    "    print(f\"Trama (Plot) (primeros 200 caracteres): {df.loc[indice, 'Plot'][:200]}...\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflexión Parte 1: Recuperación con TF-IDF\n",
    "En esta parte, implementamos un modelo TF-IDF para calcular la relevancia de términos dentro del dataset de tramas de películas. El enfoque resultó efectivo para identificar documentos relacionados directamente con las palabras clave, aunque su capacidad es limitada frente a términos no exactos o con ambigüedades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 Recuperación con BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 1: Importación de Librerías para Configuración de Elasticsearch**\n",
    "En esta celda se importan las librerías necesarias para trabajar con Elasticsearch, así como para facilitar el manejo y procesamiento de datos.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **`Elasticsearch`**:\n",
    "   - Permite interactuar con un clúster de Elasticsearch para crear índices, almacenar documentos y realizar consultas.\n",
    "   \n",
    "2. **`pandas`**:\n",
    "   - Facilita la manipulación del dataset para indexarlo en Elasticsearch.\n",
    "\n",
    "3. **`tqdm`**:\n",
    "   - Proporciona barras de progreso para monitorear la indexación de documentos.\n",
    "\n",
    "4. **`time`**:\n",
    "   - Se utiliza para medir tiempos de ejecución o manejar retrasos si es necesario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "from elasticsearch import Elasticsearch  # Para interactuar con Elasticsearch\n",
    "import pandas as pd  # Para manejar y procesar datos\n",
    "from tqdm import tqdm  # Para mostrar barras de progreso\n",
    "import time  # Para medir tiempos de ejecución\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 2: Conexión con Elasticsearch**\n",
    "En esta celda se configura la conexión al servidor local de Elasticsearch para asegurarse de que esté listo para indexar documentos y realizar consultas.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Conexión**:\n",
    "   - Se establece la conexión al servidor de Elasticsearch utilizando la URL `http://localhost:9200`.\n",
    "   \n",
    "2. **Verificación**:\n",
    "   - Se utiliza el método `ping()` para comprobar si el servidor de Elasticsearch está accesible.\n",
    "   - Se imprime un mensaje indicando si la conexión fue exitosa o fallida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado a Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "# Conectar con Elasticsearch\n",
    "\n",
    "# Configuramos la conexión con Elasticsearch\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "\n",
    "# Verificamos la conexión\n",
    "if es.ping():\n",
    "    print(\"Conectado a Elasticsearch\")\n",
    "else:\n",
    "    print(\"No se pudo conectar a Elasticsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 3: Configuración del Índice en Elasticsearch**\n",
    "En esta celda se configura y crea un índice en Elasticsearch para almacenar los documentos del dataset, con ajustes específicos para mejorar la búsqueda basada en BM25.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Nombre del índice**:\n",
    "   - Se define el nombre del índice como `\"movie_plots\"`.\n",
    "\n",
    "2. **Configuración del índice**:\n",
    "   - **`settings`**:\n",
    "     - `number_of_shards`: Número de fragmentos del índice (1 en este caso).\n",
    "     - `number_of_replicas`: Número de réplicas del índice (0 para evitar réplicas en este ejemplo).\n",
    "     - `analysis`: Define un analizador personalizado con soporte para stopwords en inglés.\n",
    "   - **`mappings`**:\n",
    "     - Especifica los campos del índice (`Title` y `Plot`) como texto (`text`) y les asigna el analizador personalizado.\n",
    "\n",
    "3. **Creación del índice**:\n",
    "   - Verifica si el índice ya existe:\n",
    "     - Si no existe, lo crea utilizando la configuración definida.\n",
    "     - Si ya existe, imprime un mensaje indicando su existencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El índice 'movie_plots' ya existe.\n"
     ]
    }
   ],
   "source": [
    "# Configuración del índice para almacenar los documentos\n",
    "index_name = \"movie_plots\"\n",
    "\n",
    "# Definir el esquema del índice con mapeos para BM25\n",
    "index_config = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,  # Número de fragmentos\n",
    "        \"number_of_replicas\": 0,  # Número de réplicas\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"custom_analyzer\": {\n",
    "                    \"type\": \"standard\",  # Tipo de analizador\n",
    "                    \"stopwords\": \"_english_\"  # Stopwords en inglés\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"Title\": {\"type\": \"text\", \"analyzer\": \"custom_analyzer\"},  # Campo 'Title'\n",
    "            \"Plot\": {\"type\": \"text\", \"analyzer\": \"custom_analyzer\"}  # Campo 'Plot'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Crear el índice en Elasticsearch\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=index_config)\n",
    "    print(f\"Índice '{index_name}' creado exitosamente.\")\n",
    "else:\n",
    "    print(f\"El índice '{index_name}' ya existe.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 4: Carga del Dataset e Indexación de Documentos**\n",
    "En esta celda se carga el dataset, se filtran las filas necesarias, y los documentos se indexan en el índice previamente configurado en Elasticsearch.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Carga del dataset**:\n",
    "   - Se lee el archivo `wiki_movie_plots_deduped.csv` en un DataFrame de `pandas`.\n",
    "   \n",
    "2. **Filtrado**:\n",
    "   - Se eliminan las filas que tienen valores nulos en la columna `Plot`, ya que esta columna es esencial para las búsquedas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexando documentos en Elasticsearch: 100%|██████████| 34886/34886 [38:04<00:00, 15.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han indexado 34886 documentos en el índice 'movie_plots'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "ruta_dataset = \"wiki_movie_plots_deduped.csv\"\n",
    "df = pd.read_csv(ruta_dataset)\n",
    "\n",
    "# Filtrar filas con valores nulos en 'Plot'\n",
    "df = df.dropna(subset=['Plot'])\n",
    "\n",
    "# Insertar documentos en el índice de Elasticsearch\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Indexando documentos en Elasticsearch\"):\n",
    "    doc = {\n",
    "        \"Title\": row['Title'],  # Título de la película\n",
    "        \"Plot\": row['Plot']  # Trama de la película\n",
    "    }\n",
    "    es.index(index=index_name, id=i, body=doc)\n",
    "\n",
    "# Confirmar la cantidad de documentos indexados\n",
    "print(f\"Se han indexado {len(df)} documentos en el índice '{index_name}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 5: Función para Realizar Búsquedas con BM25**\n",
    "Esta celda define una función para realizar búsquedas en el índice de Elasticsearch utilizando el modelo de recuperación BM25. La función permite encontrar los documentos más relevantes según los términos de búsqueda proporcionados.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Consulta al índice**:\n",
    "   - Se utiliza una consulta `match` en el campo `Plot` para buscar coincidencias basadas en los términos de la consulta.\n",
    "\n",
    "2. **Parámetros de la función**:\n",
    "   - `consulta` (str): Términos de búsqueda que se usarán para recuperar documentos.\n",
    "   - `numero_resultados` (int): Cantidad máxima de resultados relevantes a devolver (por defecto, 5).\n",
    "\n",
    "3. **Procesamiento de resultados**:\n",
    "   - La respuesta de Elasticsearch incluye los documentos más relevantes y sus puntuaciones de relevancia (`_score`).\n",
    "   - La función organiza los resultados en una lista de diccionarios con las claves `Title`, `Plot` y `Score`.\n",
    "\n",
    "4. **Retorno**:\n",
    "   - Una lista de documentos relevantes, cada uno con su título, trama y puntuación de relevancia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_con_bm25(consulta, numero_resultados=5):\n",
    "    \"\"\"\n",
    "    Realiza una consulta al índice en Elasticsearch utilizando BM25.\n",
    "    \n",
    "    Args:\n",
    "        consulta (str): Términos de búsqueda.\n",
    "        numero_resultados (int): Número de resultados a retornar.\n",
    "    \n",
    "    Returns:\n",
    "        resultados (list): Lista de documentos relevantes con título, trama y puntuación.\n",
    "    \"\"\"\n",
    "    # Definir la consulta para Elasticsearch\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"Plot\": consulta  # Buscar coincidencias en la trama\n",
    "            }\n",
    "        },\n",
    "        \"size\": numero_resultados  # Número de resultados a retornar\n",
    "    }\n",
    "\n",
    "    # Realizar la consulta al índice\n",
    "    respuesta = es.search(index=index_name, body=query)\n",
    "\n",
    "    # Procesar los resultados\n",
    "    resultados = []\n",
    "    for hit in respuesta['hits']['hits']:\n",
    "        resultados.append({\n",
    "            \"Title\": hit['_source']['Title'],  # Título del documento\n",
    "            \"Plot\": hit['_source']['Plot'],  # Trama del documento\n",
    "            \"Score\": hit['_score']  # Puntuación de relevancia\n",
    "        })\n",
    "    \n",
    "    return resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 6: Ejemplo de Consulta con BM25**\n",
    "En esta celda se realiza un ejemplo de consulta al índice en Elasticsearch utilizando el modelo BM25. El objetivo es recuperar los documentos más relevantes para una consulta específica y mostrar detalles útiles sobre ellos.\n",
    "\n",
    "#### Detalles clave:\n",
    "1. **Consulta de ejemplo**:\n",
    "   - La consulta `\"dinosaurs\"` se utiliza para probar la funcionalidad del sistema de búsqueda.\n",
    "\n",
    "2. **Recuperación de documentos**:\n",
    "   - La función `buscar_con_bm25` devuelve los documentos más relevantes y sus puntuaciones.\n",
    "\n",
    "3. **Visualización de resultados**:\n",
    "   - Por cada documento relevante, se imprime:\n",
    "     - **Rango**: La posición del documento en el ranking.\n",
    "     - **Título**: El título de la película.\n",
    "     - **Puntuación (Score)**: La relevancia del documento calculada por BM25.\n",
    "     - **Trama**: Los primeros 200 caracteres de la trama, para evitar saturar la salida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para la consulta: 'dinosaurs'\n",
      "\n",
      "Rank 1\n",
      "Título: We're Back! A Dinosaur's Story\n",
      "Score: 12.8495\n",
      "Trama (primeros 200 caracteres): In present-day New York City, an Eastern bluebird named Buster runs away from his siblings and he meets an intelligent orange Tyrannosaurus named Rex, who is playing golf. He explains to Buster that h...\n",
      "--------------------------------------------------\n",
      "Rank 2\n",
      "Título: Theodore Rex\n",
      "Score: 11.7067\n",
      "Trama (primeros 200 caracteres): In an alternate futuristic society where humans and anthropomorphic dinosaurs co-exist, a tough police detective named Katie Coltraine (Whoopi Goldberg) is paired with a Tyrannosaurus named Theodore R...\n",
      "--------------------------------------------------\n",
      "Rank 3\n",
      "Título: Future War\n",
      "Score: 11.5786\n",
      "Trama (primeros 200 caracteres): Future War begins aboard a spaceship undergoing a revolt. A man enters and activates an escape pod which travels to Earth and crashes into the Pacific Ocean. The pod contains “The Runaway”, a human sl...\n",
      "--------------------------------------------------\n",
      "Rank 4\n",
      "Título: Unknown Island\n",
      "Score: 11.2436\n",
      "Trama (primeros 200 caracteres): Adventure-seeker Ted Osborne (Phillip Reed) and his fiancee Carole (Virginia Grey) are at a cafe in Singapore, looking for a charter to an island supposedly inhabited by dinosaurs. They come across th...\n",
      "--------------------------------------------------\n",
      "Rank 5\n",
      "Título: The Dinosaur Project\n",
      "Score: 11.2436\n",
      "Trama (primeros 200 caracteres): A group of explorers from the British Cryptozoological Society goes on an expedition into the Congo in search of a cryptid—the so-called Mokele-mbembe—which is believed to be a Plesiosaur. Along with ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de consulta con BM25\n",
    "consulta_ejemplo = \"dinosaurs\"\n",
    "\n",
    "# Obtener los documentos más relevantes\n",
    "resultados_bm25 = buscar_con_bm25(consulta_ejemplo, numero_resultados=5)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Resultados para la consulta: '{consulta_ejemplo}'\\n\")\n",
    "for rank, resultado in enumerate(resultados_bm25, start=1):\n",
    "    print(f\"Rank {rank}\")\n",
    "    print(f\"Título: {resultado['Title']}\")\n",
    "    print(f\"Score: {resultado['Score']:.4f}\")\n",
    "    print(f\"Trama (primeros 200 caracteres): {resultado['Plot'][:200]}...\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflexión Parte 2: Recuperación con BM25\n",
    "Usamos Elasticsearch para implementar BM25, lo que permitió una recuperación más robusta que TF-IDF al considerar la saturación de términos y la longitud de los documentos. Esta técnica mostró mejores resultados al priorizar documentos más relevantes para consultas específicas como \"dinosaurs\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: Recuperación con FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 1: Preparación de datos**  \n",
    "Esta etapa consiste en preparar los datos para su posterior procesamiento:  \n",
    "- Se carga un dataset que contiene tramas y títulos de películas.  \n",
    "- Se eliminan filas con valores nulos en la columna `Plot` para evitar errores.  \n",
    "- Se crea una nueva columna, `texto_completo`, combinando el título y la trama de cada película. Esto asegura que toda la información relevante esté en un solo campo para la recuperación posterior.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 1: Preparación de datos\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cargar el dataset\n",
    "ruta_dataset = \"wiki_movie_plots_deduped.csv\"\n",
    "df = pd.read_csv(ruta_dataset)\n",
    "\n",
    "# Eliminar filas con valores nulos en la columna 'Plot'\n",
    "df = df.dropna(subset=['Plot'])\n",
    "\n",
    "# Crear la columna 'texto_completo' combinando 'Title' y 'Plot'\n",
    "df['texto_completo'] = df['Title'].astype(str) + \" \" + df['Plot'].astype(str)\n",
    "\n",
    "# Verificar que 'texto_completo' fue creado correctamente\n",
    "print(\"Columnas disponibles:\", df.columns)\n",
    "print(\"Ejemplo de texto completo:\", df['texto_completo'].head())\n",
    "\n",
    "# Parte 2: Generación de embeddings con SentenceTransformer\n",
    "modelo_embeddings = SentenceTransformer('all-MiniLM-L6-v2')  # Puedes usar otro modelo según necesidad\n",
    "\n",
    "# Convertir los textos en vectores\n",
    "textos = df['texto_completo'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 2: Generación de embeddings con SentenceTransformer**  \n",
    "En este paso, los datos procesados son convertidos a representaciones vectoriales llamadas embeddings:  \n",
    "- Se utiliza el modelo `SentenceTransformer` para representar semánticamente los textos combinados.  \n",
    "- El progreso de la generación de embeddings se muestra mediante una barra de carga (`tqdm`) para facilitar el monitoreo.  \n",
    "- Estos embeddings serán usados más adelante para realizar búsquedas eficientes basadas en similitud.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles: Index(['Release Year', 'Title', 'Origin/Ethnicity', 'Director', 'Cast',\n",
      "       'Genre', 'Wiki Page', 'Plot', 'texto_completo'],\n",
      "      dtype='object')\n",
      "Ejemplo de texto completo: 0    Kansas Saloon Smashers A bartender is working ...\n",
      "1    Love by the Light of the Moon The moon, painte...\n",
      "2    The Martyred Presidents The film, just over a ...\n",
      "3    Terrible Teddy, the Grizzly King Lasting just ...\n",
      "4    Jack and the Beanstalk The earliest known adap...\n",
      "Name: texto_completo, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando embeddings: 100%|██████████| 34886/34886 [36:17<00:00, 16.02it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agregando embeddings al índice FAISS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexando en FAISS: 100%|██████████| 34886/34886 [00:00<00:00, 135553.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Índice FAISS creado con 34886 vectores.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Generar embeddings y mostrar progreso\n",
    "embeddings = []\n",
    "for texto in tqdm(textos, desc=\"Generando embeddings\"):\n",
    "    embeddings.append(modelo_embeddings.encode(texto, convert_to_numpy=True))\n",
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Parte 3: Configurar FAISS**  \n",
    "Aquí se configura un índice FAISS para permitir búsquedas rápidas de similitud entre vectores:  \n",
    "- Se utiliza la métrica L2 (distancia euclidiana cuadrada) para medir similitudes entre vectores.  \n",
    "- Los embeddings generados previamente se añaden al índice en un proceso que muestra su progreso con una barra de carga (`tqdm`).  \n",
    "- Una vez creado, el índice contiene todos los vectores necesarios para las búsquedas futuras.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parte 3: Configurar FAISS\n",
    "# Crear el índice en FAISS (usamos L2 para búsqueda más rápida)\n",
    "dimension = embeddings.shape[1]  # Dimensión de los vectores\n",
    "indice_faiss = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Agregar los embeddings al índice con barra de progreso\n",
    "print(\"\\nAgregando embeddings al índice FAISS:\")\n",
    "for i in tqdm(range(len(embeddings)), desc=\"Indexando en FAISS\"):\n",
    "    indice_faiss.add(np.expand_dims(embeddings[i], axis=0))\n",
    "\n",
    "print(f\"\\nÍndice FAISS creado con {indice_faiss.ntotal} vectores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Parte 4: Realizar consultas en FAISS**  \n",
    "En esta etapa, se ejecutan búsquedas en el índice FAISS:  \n",
    "- Una consulta textual es convertida en un vector de embedding utilizando el mismo modelo de SentenceTransformer.  \n",
    "- FAISS busca en su índice los vectores más cercanos al vector de la consulta y devuelve los resultados más relevantes.  \n",
    "- Cada resultado incluye el título, la trama y una métrica de similitud (distancia).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte 4: Consultas en FAISS\n",
    "def buscar_con_faiss(consulta, numero_resultados=5):\n",
    "    \"\"\"\n",
    "    Realiza una consulta en FAISS buscando los vectores más cercanos.\n",
    "    \"\"\"\n",
    "    # Convertir la consulta a un vector de embedding\n",
    "    vector_consulta = modelo_embeddings.encode([consulta], convert_to_numpy=True)\n",
    "    \n",
    "    # Buscar los vecinos más cercanos en FAISS\n",
    "    distancias, indices = indice_faiss.search(vector_consulta, numero_resultados)\n",
    "    \n",
    "    resultados = []\n",
    "    for indice, distancia in zip(indices[0], distancias[0]):\n",
    "        resultados.append({\n",
    "            \"Title\": df.iloc[indice]['Title'],\n",
    "            \"Plot\": df.iloc[indice]['Plot'],\n",
    "            \"Distancia\": distancia\n",
    "        })\n",
    "    return resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Parte 5: Comparar resultados de TF-IDF, BM25 y FAISS**  \n",
    "En esta etapa, se comparan los resultados obtenidos utilizando las técnicas TF-IDF, BM25 y FAISS:  \n",
    "- Para TF-IDF y BM25, se calculan las puntuaciones de relevancia de los documentos recuperados.  \n",
    "- Para FAISS, se utiliza la métrica de distancia para identificar los documentos más cercanos.  \n",
    "- Los cuatro primeros resultados de cada técnica son mostrados junto con sus métricas respectivas, permitiendo una comparación clara de su efectividad.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados para la consulta: 'A park with cloned dinosaurs'\n",
      "\n",
      "Rank 1\n",
      "Título: Jurassic Park\n",
      "Distancia: 0.6588\n",
      "Trama (primeros 200 caracteres): Industrialist John Hammond and his bioengineering company, InGen, have created a theme park called Jurassic Park on Isla Nublar, a Costa Rican island, populated with cloned dinosaurs. After one of the...\n",
      "--------------------------------------------------\n",
      "Rank 2\n",
      "Título: Dinosaurs! – A Fun-Filled Trip Back in Time!\n",
      "Distancia: 1.0297\n",
      "Trama (primeros 200 caracteres): The video—with beginning scenes filmed in 1987—begins with a young boy named Phillip (played by Fred Savage) sitting in his bedroom, listening to loud music, and struggling to find an idea for a class...\n",
      "--------------------------------------------------\n",
      "Rank 3\n",
      "Título: Jurassic World\n",
      "Distancia: 1.0311\n",
      "Trama (primeros 200 caracteres): Brothers Zach and Gray Mitchell visit Isla Nublar, the site of the original Jurassic Park, where a new theme park named Jurassic World has operated for years. Simon Masrani, the park's owner, has enco...\n",
      "--------------------------------------------------\n",
      "Rank 4\n",
      "Título: Jurassic Park III\n",
      "Distancia: 1.0853\n",
      "Trama (primeros 200 caracteres): Ben Hildebrand and 12-year-old Eric Kirby go parasailing around the waters of Isla Sorna. The boat crew mysteriously disappear in a brief moment obscured by fog, forcing Ben to detach the line; he and...\n",
      "--------------------------------------------------\n",
      "Rank 5\n",
      "Título: Legend of Dinosaurs & Monster Birds\n",
      "Distancia: 1.0999\n",
      "Trama (primeros 200 caracteres): A young woman wanders barefoot in the lush Aokigahara (青木ヶ原), also known as the Sea of Trees (樹海 Jukai) region of Mt. Fuji, and suddenly falls into an underground cavern, awakening in an icy cave full...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de consulta\n",
    "consulta_ejemplo = \"A park with cloned dinosaurs\"\n",
    "resultados_faiss = buscar_con_faiss(consulta_ejemplo, numero_resultados=5)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"\\nResultados para la consulta: '{consulta_ejemplo}'\\n\")\n",
    "for rank, resultado in enumerate(resultados_faiss, start=1):\n",
    "    print(f\"Rank {rank}\")\n",
    "    print(f\"Título: {resultado['Title']}\")\n",
    "    print(f\"Distancia: {resultado['Distancia']:.4f}\")\n",
    "    print(f\"Trama (primeros 200 caracteres): {resultado['Plot'][:200]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Ejemplo de Consulta y Comparación**  \n",
    "Se ejecuta una consulta específica, como \"A park with cloned dinosaurs\", y se compara el rendimiento de las tres técnicas.  \n",
    "- Se presentan los títulos, tramas (truncadas para legibilidad) y métricas de relevancia para los cuatro mejores resultados obtenidos por cada técnica.  \n",
    "- Esto permite evaluar cuál de las estrategias ofrece una recuperación más relevante para el usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación de resultados para la consulta: 'A park with cloned dinosaurs'\n",
      "\n",
      "Resultados con TF-IDF:\n",
      "Rank 1: Theodore Rex (Score: 0.2996)\n",
      "Trama: In an alternate futuristic society where humans and anthropomorphic dinosaurs co-exist, a tough police detective named Katie Coltraine (Whoopi Goldberg) is paired with a Tyrannosaurus named Theodore R...\n",
      "--------------------------------------------------\n",
      "Rank 2: We're Back! A Dinosaur's Story (Score: 0.2416)\n",
      "Trama: In present-day New York City, an Eastern bluebird named Buster runs away from his siblings and he meets an intelligent orange Tyrannosaurus named Rex, who is playing golf. He explains to Buster that h...\n",
      "--------------------------------------------------\n",
      "Rank 3: Jurassic Park (Score: 0.2376)\n",
      "Trama: Industrialist John Hammond and his bioengineering company, InGen, have created a theme park called Jurassic Park on Isla Nublar, a Costa Rican island, populated with cloned dinosaurs. After one of the...\n",
      "--------------------------------------------------\n",
      "Rank 4: Dinosaurs! – A Fun-Filled Trip Back in Time! (Score: 0.2237)\n",
      "Trama: The video—with beginning scenes filmed in 1987—begins with a young boy named Phillip (played by Fred Savage) sitting in his bedroom, listening to loud music, and struggling to find an idea for a class...\n",
      "--------------------------------------------------\n",
      "\n",
      "Resultados con BM25:\n",
      "Rank 1: Jurassic Park (Score: 22.3337)\n",
      "Trama: Industrialist John Hammond and his bioengineering company, InGen, have created a theme park called Jurassic Park on Isla Nublar, a Costa Rican island, populated with cloned dinosaurs. After one of the...\n",
      "--------------------------------------------------\n",
      "Rank 2: The Lost World: Jurassic Park (Score: 15.8991)\n",
      "Trama: On Isla Sorna, an island off the Costa Rican coast, a young girl named Cathy Bowman wanders around during a family vacation, and survives an attack by a swarm of Compsognathus. Her parents file a laws...\n",
      "--------------------------------------------------\n",
      "Rank 3: We're Back! A Dinosaur's Story (Score: 15.1359)\n",
      "Trama: In present-day New York City, an Eastern bluebird named Buster runs away from his siblings and he meets an intelligent orange Tyrannosaurus named Rex, who is playing golf. He explains to Buster that h...\n",
      "--------------------------------------------------\n",
      "Rank 4: Jurassic World (Score: 14.8756)\n",
      "Trama: Brothers Zach and Gray Mitchell visit Isla Nublar, the site of the original Jurassic Park, where a new theme park named Jurassic World has operated for years. Simon Masrani, the park's owner, has enco...\n",
      "--------------------------------------------------\n",
      "\n",
      "Resultados con FAISS:\n",
      "Rank 1: Jurassic Park (Distancia: 0.6588)\n",
      "Trama: Industrialist John Hammond and his bioengineering company, InGen, have created a theme park called Jurassic Park on Isla Nublar, a Costa Rican island, populated with cloned dinosaurs. After one of the...\n",
      "--------------------------------------------------\n",
      "Rank 2: Dinosaurs! – A Fun-Filled Trip Back in Time! (Distancia: 1.0297)\n",
      "Trama: The video—with beginning scenes filmed in 1987—begins with a young boy named Phillip (played by Fred Savage) sitting in his bedroom, listening to loud music, and struggling to find an idea for a class...\n",
      "--------------------------------------------------\n",
      "Rank 3: Jurassic World (Distancia: 1.0311)\n",
      "Trama: Brothers Zach and Gray Mitchell visit Isla Nublar, the site of the original Jurassic Park, where a new theme park named Jurassic World has operated for years. Simon Masrani, the park's owner, has enco...\n",
      "--------------------------------------------------\n",
      "Rank 4: Jurassic Park III (Distancia: 1.0853)\n",
      "Trama: Ben Hildebrand and 12-year-old Eric Kirby go parasailing around the waters of Isla Sorna. The boat crew mysteriously disappear in a brief moment obscured by fog, forcing Ben to detach the line; he and...\n",
      "--------------------------------------------------\n",
      "\n",
      "Reflexión:\n",
      "- TF-IDF se basa en términos exactos y puede ser menos efectivo para consultas más generales o semánticas.\n",
      "- BM25 mejora TF-IDF al considerar saturación de términos y longitud de documentos, priorizando mejor las coincidencias.\n",
      "- FAISS utiliza embeddings y captura la semántica de la consulta, siendo ideal para consultas donde las palabras exactas no coinciden con los documentos.\n"
     ]
    }
   ],
   "source": [
    "# Función para comparar resultados de TF-IDF, BM25 y FAISS\n",
    "def comparar_resultados(consulta, numero_resultados=4):\n",
    "    \"\"\"\n",
    "    Compara los resultados obtenidos con TF-IDF, BM25 y FAISS y muestra los 4 primeros de cada técnica.\n",
    "    \"\"\"\n",
    "    print(f\"\\nComparación de resultados para la consulta: '{consulta}'\\n\")\n",
    "    \n",
    "    # TF-IDF\n",
    "    indices_tfidf, puntuaciones_tfidf = buscar_con_tfidf(consulta, numero_resultados)\n",
    "    resultados_tfidf = [\n",
    "        {\"Rank\": rank + 1, \n",
    "         \"Title\": df.loc[indice, 'Title'], \n",
    "         \"Score\": puntuacion, \n",
    "         \"Plot\": df.loc[indice, 'Plot'][:200]}\n",
    "        for rank, (indice, puntuacion) in enumerate(zip(indices_tfidf, puntuaciones_tfidf))\n",
    "    ]\n",
    "    print(\"Resultados con TF-IDF:\")\n",
    "    for resultado in resultados_tfidf:\n",
    "        print(f\"Rank {resultado['Rank']}: {resultado['Title']} (Score: {resultado['Score']:.4f})\")\n",
    "        print(f\"Trama: {resultado['Plot']}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # BM25\n",
    "    resultados_bm25 = buscar_con_bm25(consulta, numero_resultados)\n",
    "    print(\"\\nResultados con BM25:\")\n",
    "    for rank, resultado in enumerate(resultados_bm25, start=1):\n",
    "        print(f\"Rank {rank}: {resultado['Title']} (Score: {resultado['Score']:.4f})\")\n",
    "        print(f\"Trama: {resultado['Plot'][:200]}...\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # FAISS\n",
    "    resultados_faiss = buscar_con_faiss(consulta, numero_resultados)\n",
    "    print(\"\\nResultados con FAISS:\")\n",
    "    for rank, resultado in enumerate(resultados_faiss, start=1):\n",
    "        print(f\"Rank {rank}: {resultado['Title']} (Distancia: {resultado['Distancia']:.4f})\")\n",
    "        print(f\"Trama: {resultado['Plot'][:200]}...\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Ejemplo de comparación mostrando los 4 primeros resultados\n",
    "consulta_ejemplo = \"A park with cloned dinosaurs\"\n",
    "comparar_resultados(consulta_ejemplo, numero_resultados=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
